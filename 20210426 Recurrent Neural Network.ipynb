{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"20210426 Recurrent Neural Network","provenance":[],"authorship_tag":"ABX9TyNeJeG5XW7WQmNJ2xlJy+/m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AT7J8_Tunch9","executionInfo":{"status":"ok","timestamp":1619437640629,"user_tz":-60,"elapsed":8985,"user":{"displayName":"Martyn Bonham-Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4a9GG8wAR2gMnLtqnmgQ8OVYw5FjASqtmrY1TJg=s64","userId":"18107048213332032199"}},"outputId":"5ee109ab-12a4-4fcb-a04e-40d7bac98e6c"},"source":["#Step 1: Import our dataset\n","from keras.datasets import imdb #IMBD built-in dataset in Keras\n","\n","#Set vocaab size\n","vocabulary_size = 5000\n","\n","#Load in training and test sets\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n","\n","print('We have imported {} training samples and {} test samples.'.format(len(X_train), len(X_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"],"name":"stderr"},{"output_type":"stream","text":["We have imported 25000 training samples and 25000 test samples.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cizc3LlDpL5s","executionInfo":{"status":"ok","timestamp":1619437640631,"user_tz":-60,"elapsed":8952,"user":{"displayName":"Martyn Bonham-Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4a9GG8wAR2gMnLtqnmgQ8OVYw5FjASqtmrY1TJg=s64","userId":"18107048213332032199"}},"outputId":"a3e84465-a836-402b-c416-4104308d4aa2"},"source":["#Inspect a sample review & it's label\n","print(X_train[7])\n","print('----Label----')\n","print(y_train[7])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[1, 4, 2, 716, 4, 65, 7, 4, 689, 4367, 2, 2343, 4804, 2, 2, 2, 2, 2315, 2, 2, 2, 2, 4, 2, 628, 2, 37, 9, 150, 4, 2, 4069, 11, 2909, 4, 2, 847, 313, 6, 176, 2, 9, 2, 138, 9, 4434, 19, 4, 96, 183, 26, 4, 192, 15, 27, 2, 799, 2, 2, 588, 84, 11, 4, 3231, 152, 339, 2, 42, 4869, 2, 2, 345, 4804, 2, 142, 43, 218, 208, 54, 29, 853, 659, 46, 4, 882, 183, 80, 115, 30, 4, 172, 174, 10, 10, 1001, 398, 1001, 1055, 526, 34, 3717, 2, 2, 2, 17, 4, 2, 1094, 871, 64, 85, 22, 2030, 1109, 38, 230, 9, 4, 4324, 2, 251, 2, 1034, 195, 301, 14, 16, 31, 7, 4, 2, 8, 783, 2, 33, 4, 2945, 103, 465, 2, 42, 845, 45, 446, 11, 1895, 19, 184, 76, 32, 4, 2, 207, 110, 13, 197, 4, 2, 16, 601, 964, 2152, 595, 13, 258, 4, 1730, 66, 338, 55, 2, 4, 550, 728, 65, 1196, 8, 1839, 61, 1546, 42, 2, 61, 602, 120, 45, 2, 6, 320, 786, 99, 196, 2, 786, 2, 4, 225, 4, 373, 1009, 33, 4, 130, 63, 69, 72, 1104, 46, 1292, 225, 14, 66, 194, 2, 1703, 56, 8, 803, 1004, 6, 2, 155, 11, 4, 2, 3231, 45, 853, 2029, 8, 30, 6, 117, 430, 19, 6, 2, 9, 15, 66, 424, 8, 2337, 178, 9, 15, 66, 424, 8, 1465, 178, 9, 15, 66, 142, 15, 9, 424, 8, 28, 178, 662, 44, 12, 17, 4, 130, 898, 1686, 9, 6, 2, 267, 185, 430, 4, 118, 2, 277, 15, 4, 1188, 100, 216, 56, 19, 4, 357, 114, 2, 367, 45, 115, 93, 788, 121, 4, 2, 79, 32, 68, 278, 39, 8, 818, 162, 4165, 237, 600, 7, 98, 306, 8, 157, 549, 628, 11, 6, 2, 13, 824, 15, 4104, 76, 42, 138, 36, 774, 77, 1059, 159, 150, 4, 229, 497, 8, 1493, 11, 175, 251, 453, 19, 2, 189, 12, 43, 127, 6, 394, 292, 7, 2, 4, 107, 8, 4, 2826, 15, 1082, 1251, 9, 906, 42, 1134, 6, 66, 78, 22, 15, 13, 244, 2519, 8, 135, 233, 52, 44, 10, 10, 466, 112, 398, 526, 34, 4, 1572, 4413, 2, 1094, 225, 57, 599, 133, 225, 6, 227, 7, 541, 4323, 6, 171, 139, 7, 539, 2, 56, 11, 6, 3231, 21, 164, 25, 426, 81, 33, 344, 624, 19, 6, 4617, 7, 2, 2, 6, 2, 4, 22, 9, 1082, 629, 237, 45, 188, 6, 55, 655, 707, 2, 956, 225, 1456, 841, 42, 1310, 225, 6, 2493, 1467, 2, 2828, 21, 4, 2, 9, 364, 23, 4, 2228, 2407, 225, 24, 76, 133, 18, 4, 189, 2293, 10, 10, 814, 11, 2, 11, 2642, 14, 47, 15, 682, 364, 352, 168, 44, 12, 45, 24, 913, 93, 21, 247, 2441, 4, 116, 34, 35, 1859, 8, 72, 177, 9, 164, 8, 901, 344, 44, 13, 191, 135, 13, 126, 421, 233, 18, 259, 10, 10, 4, 2, 2, 4, 2, 3074, 7, 112, 199, 753, 357, 39, 63, 12, 115, 2, 763, 8, 15, 35, 3282, 1523, 65, 57, 599, 6, 1916, 277, 1730, 37, 25, 92, 202, 6, 2, 44, 25, 28, 6, 22, 15, 122, 24, 4171, 72, 33, 32]\n","----Label----\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8i8lIsYpaFP","executionInfo":{"status":"ok","timestamp":1619437640635,"user_tz":-60,"elapsed":8915,"user":{"displayName":"Martyn Bonham-Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4a9GG8wAR2gMnLtqnmgQ8OVYw5FjASqtmrY1TJg=s64","userId":"18107048213332032199"}},"outputId":"e5ff9f2d-2f0c-4a7d-e4b3-895dcbe5a172"},"source":["#At the moment all words are represented by integers. We can undo this. \n","\n","word2id = imdb.get_word_index()\n","id2word = {i : word for word, i in word2id.items()}\n","print('----Review with words ----')\n","print([id2word.get(i, ' ') for i in X_train[7]])\n","print('----Label----')\n","print(y_train[7])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1646592/1641221 [==============================] - 0s 0us/step\n","----Review with words ----\n","['the', 'of', 'and', 'local', 'of', 'their', 'br', 'of', 'attention', 'widow', 'and', 'captures', 'parties', 'and', 'and', 'and', 'and', 'excitement', 'and', 'and', 'and', 'and', 'of', 'and', 'english', 'and', 'like', 'it', 'years', 'of', 'and', 'unintentional', 'this', 'hitchcock', 'of', 'and', 'learn', 'everyone', 'is', 'quite', 'and', 'it', 'and', 'such', 'it', 'bonus', 'film', 'of', 'too', 'seems', 'he', 'of', 'enough', 'for', 'be', 'and', 'editing', 'and', 'and', 'please', 'great', 'this', 'of', 'shoots', 'thing', '3', 'and', \"it's\", 'mentioning', 'and', 'and', 'given', 'parties', 'and', 'back', 'out', 'interesting', 'times', 'no', 'all', 'average', 'talking', 'some', 'of', 'nor', 'seems', 'into', 'best', 'at', 'of', 'every', 'cast', 'i', 'i', 'inside', 'keep', 'inside', 'large', 'viewer', 'who', 'obscure', 'and', 'and', 'and', 'movie', 'of', 'and', 'entirely', \"you've\", 'see', 'because', 'you', 'deals', 'successful', 'her', 'anything', 'it', 'of', 'dedicated', 'and', 'hard', 'and', 'further', \"that's\", 'takes', 'as', 'with', 'by', 'br', 'of', 'and', 'in', 'minute', 'and', 'they', 'of', 'westerns', 'watch', 'seemed', 'and', \"it's\", 'lee', 'if', 'oh', 'this', 'japan', 'film', 'around', 'get', 'an', 'of', 'and', 'always', 'life', 'was', 'between', 'of', 'and', 'with', 'group', 'rate', 'code', \"film's\", 'was', 'although', 'of', 'arts', 'had', 'death', 'time', 'and', 'of', 'anyway', 'romantic', 'their', 'won', 'in', 'kevin', 'only', 'flying', \"it's\", 'and', 'only', 'cut', 'show', 'if', 'and', 'is', 'star', 'stay', 'movies', 'both', 'and', 'stay', 'and', 'of', 'music', 'of', 'tell', 'missing', 'they', 'of', 'here', 'really', 'me', 'we', 'value', 'some', 'silent', 'music', 'as', 'had', 'thought', 'and', 'realized', 'she', 'in', 'sorry', 'reasons', 'is', 'and', '10', 'this', 'of', 'and', 'shoots', 'if', 'average', 'remembered', 'in', 'at', 'is', 'over', 'worse', 'film', 'is', 'and', 'it', 'for', 'had', 'absolutely', 'in', 'naive', 'want', 'it', 'for', 'had', 'absolutely', 'in', 'j', 'want', 'it', 'for', 'had', 'back', 'for', 'it', 'absolutely', 'in', 'one', 'want', 'shots', 'has', 'that', 'movie', 'of', 'here', 'write', 'whatsoever', 'it', 'is', 'and', 'set', 'got', 'worse', 'of', 'where', 'and', 'once', 'for', 'of', 'accent', 'after', 'saw', 'she', 'film', 'of', 'rest', 'little', 'and', 'camera', 'if', 'best', 'way', 'elements', 'know', 'of', 'and', 'also', 'an', 'were', 'sense', 'or', 'in', 'realistic', 'actually', 'satan', \"he's\", 'score', 'br', 'any', 'himself', 'in', 'another', 'type', 'english', 'this', 'is', 'and', 'was', 'tom', 'for', 'dating', 'get', \"it's\", 'such', 'from', 'fantastic', 'will', 'pace', 'new', 'years', 'of', 'guy', 'game', 'in', 'murders', 'this', 'us', 'hard', 'lives', 'film', 'and', 'fact', 'that', 'out', 'end', 'is', 'getting', 'together', 'br', 'and', 'of', 'seen', 'in', 'of', 'jail', 'for', 'sees', 'utterly', 'it', 'meet', \"it's\", 'depth', 'is', 'had', 'do', 'you', 'for', 'was', 'rather', 'convince', 'in', 'why', 'last', 'very', 'has', 'i', 'i', 'throughout', 'never', 'keep', 'viewer', 'who', 'of', 'becoming', 'switch', 'and', 'entirely', 'music', 'even', 'interest', 'scene', 'music', 'is', 'far', 'br', 'voice', 'riveting', 'is', 'again', 'something', 'br', 'decent', 'and', 'she', 'this', 'is', 'shoots', 'not', 'director', 'have', 'against', 'people', 'they', 'line', 'cinematography', 'film', 'is', 'couples', 'br', 'and', 'and', 'is', 'and', 'of', 'you', 'it', 'sees', 'hero', \"he's\", 'if', \"can't\", 'is', 'time', 'husband', 'silly', 'and', 'result', 'music', 'image', 'sequences', \"it's\", 'chase', 'music', 'is', 'veteran', 'include', 'and', 'freeman', 'not', 'of', 'and', 'it', 'along', 'are', 'of', 'hearing', 'cutting', 'music', 'his', 'get', 'scene', 'but', 'of', 'fact', 'correct', 'i', 'i', 'means', 'this', 'and', 'this', 'blockbuster', 'as', 'there', 'for', 'disappointed', 'along', 'wrong', 'few', 'has', 'that', 'if', 'his', 'weird', 'way', 'not', 'girl', 'display', 'of', 'love', 'who', 'so', 'friendship', 'in', 'we', 'down', 'it', 'director', 'in', 'situation', 'line', 'has', 'was', 'big', 'why', 'was', 'your', 'supposed', 'last', 'but', 'especially', 'i', 'i', 'of', 'and', 'and', 'of', 'and', 'internet', 'br', 'never', 'give', 'theme', 'rest', 'or', 'really', 'that', 'best', 'and', 'release', 'in', 'for', 'so', 'multi', 'random', 'their', 'even', 'interest', 'is', 'judge', 'once', 'arts', 'like', 'have', 'then', 'own', 'is', 'and', 'has', 'have', 'one', 'is', 'you', 'for', 'off', 'his', 'dutch', 'we', 'they', 'an']\n","----Label----\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dku6_-iPp-nW","executionInfo":{"status":"ok","timestamp":1619437641361,"user_tz":-60,"elapsed":9622,"user":{"displayName":"Martyn Bonham-Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4a9GG8wAR2gMnLtqnmgQ8OVYw5FjASqtmrY1TJg=s64","userId":"18107048213332032199"}},"outputId":"874cfe52-1106-4df3-dd5e-941796846a0a"},"source":["#What's the max and min length of any of these reviews?\n","\n","print('The max length is {}'.format(len(max((X_train + X_test), key=len))))\n","print('The min length is {}'.format(len(min((X_train + X_test), key=len))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The max length is 2697\n","The min length is 70\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jSIdlVruqLZK"},"source":["#We cannot feed these data into a RNN without making all input documents of equal length. \n","#We will limit the length to max_words by truncating longer reviews and padding shorter reviews. \n","\n","from keras.preprocessing import sequence\n","\n","max_words = 500\n","X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n","X_test = sequence.pad_sequences(X_test, maxlen = max_words)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmWlOAm_q5IH","executionInfo":{"status":"ok","timestamp":1619437643526,"user_tz":-60,"elapsed":11739,"user":{"displayName":"Martyn Bonham-Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4a9GG8wAR2gMnLtqnmgQ8OVYw5FjASqtmrY1TJg=s64","userId":"18107048213332032199"}},"outputId":"b2a2172b-1457-4ba0-e271-a07b589aad05"},"source":["#Design our RNN model! \n","\n","from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","\n","model = Sequential() #Building a sequential neural network\n","embedding_size = 32 #Not sure what this does \n","model.add(Embedding(vocabulary_size, embedding_size, input_length = max_words))\n","model.add(LSTM(100))\n","model.add(Dense(1, activation = 'sigmoid'))\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 500, 32)           160000    \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 100)               53200     \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 101       \n","=================================================================\n","Total params: 213,301\n","Trainable params: 213,301\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L3UVjK-stcWk"},"source":["Our model has 213,301 parameters to train. It includes the following:\n","\n","\n","*   Takes in the review and embeds it into a dense vector space rather than a sparse bag-of-words model, creating a dense array;\n","*   The dense array is taken by the Long Short-Term Memory layer and turned into a single vector of size 100;\n","*   The sigmoid activation function outputs a value between 0 and 1. \n","\n"]},{"cell_type":"code","metadata":{"id":"e1DEsQ72tQGd"},"source":["#Compile:\n","model.compile(optimizer='Adam', loss = 'binary_crossentropy', metrics= ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1RflZJzsuQqc"},"source":["Now we have finished compilation, we can begin *training* the model. \n","We will specify the **batch size** ```batch_size``` and the **number of training epochs** ```num_epochs```. \n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YoAROhrCuBlH","executionInfo":{"status":"ok","timestamp":1619438303920,"user_tz":-60,"elapsed":672088,"user":{"displayName":"Martyn Bonham-Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4a9GG8wAR2gMnLtqnmgQ8OVYw5FjASqtmrY1TJg=s64","userId":"18107048213332032199"}},"outputId":"9294e37d-af82-488a-a1c5-804bdceb2cd7"},"source":["batch_size = 64\n","num_epochs = 3\n","\n","#Reserve validation data - take off the last batch for use as a validation set\n","X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n","X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n","\n","#Train model!!!\n","model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size = batch_size, epochs = num_epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","390/390 [==============================] - 223s 565ms/step - loss: 0.5583 - accuracy: 0.6882 - val_loss: 0.2544 - val_accuracy: 0.9062\n","Epoch 2/3\n","390/390 [==============================] - 219s 560ms/step - loss: 0.2842 - accuracy: 0.8862 - val_loss: 0.3101 - val_accuracy: 0.8438\n","Epoch 3/3\n","390/390 [==============================] - 219s 561ms/step - loss: 0.2590 - accuracy: 0.8996 - val_loss: 0.2146 - val_accuracy: 0.9375\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fb091e48f90>"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVcrmPvJVpB_","executionInfo":{"status":"ok","timestamp":1619443358098,"user_tz":-60,"elapsed":71261,"user":{"displayName":"Martyn Bonham-Yang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi4a9GG8wAR2gMnLtqnmgQ8OVYw5FjASqtmrY1TJg=s64","userId":"18107048213332032199"}},"outputId":"be2658b1-310d-4000-81c8-e026fc021c8d"},"source":["scores = model.evaluate(X_test, y_test, verbose = 0)\n","print('Model accuracy: {}'.format(scores[1]))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model accuracy: 0.8615599870681763\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qde9tnxAV4Cs"},"source":[""],"execution_count":null,"outputs":[]}]}